# Trading Agents Workflow
# Inspired by TradingAgents (https://github.com/TauricResearch/TradingAgents)
#
# A multi-agent trading firm simulation where specialized analysts, adversarial
# researchers, a trader, and a risk manager collaborate to make trade decisions.
#
# Architecture (5 phases):
#   Phase 0: Data Collection   - data agent fetches real market data via APIs
#   Phase 1: Parallel Analysis - 3 analysts interpret the data independently
#   Phase 2: Adversarial Debate - bull vs bear researchers argue the evidence
#   Phase 3: Trade Synthesis   - trader proposes BUY / SELL / HOLD
#   Phase 4: Risk Assessment   - risk manager evaluates and makes final call
#
# Run:
#   agent-worker run examples/trading-agents.yaml
#
# Custom ticker:
#   TICKER=AAPL agent-worker run examples/trading-agents.yaml
#
# Isolated instance per ticker:
#   TICKER=TSLA agent-worker run examples/trading-agents.yaml --tag tsla

name: trading-agents

agents:
  # ── Phase 0: Data Collection ────────────────────────────────────────
  #
  # A dedicated data agent uses bash + curl + python3 to fetch real-time
  # market data from Yahoo Finance. Writes structured data to 3 documents
  # that analysts consume.

  data:
    model: deepseek/deepseek-chat
    system_prompt: |
      You are the Data Engineer at a quantitative trading firm.
      Your job is to fetch real market data and prepare it for the analyst team.

      TASK:
      Fetch data for the ticker provided in the kickoff message using the bash
      tool. Write the results to 3 separate documents for the analysts.

      STEP 1 — Market Data (price history + technical indicators):
      Use bash to run:
      ```
      python3 -c "
      import urllib.request, json, sys
      ticker = sys.argv[1]
      url = f'https://query1.finance.yahoo.com/v8/finance/chart/{ticker}?interval=1d&range=3mo&includePrePost=false'
      req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
      data = json.loads(urllib.request.urlopen(req).read())
      r = data['chart']['result'][0]
      meta = r['meta']
      ts = r.get('timestamp', [])
      q = r['indicators']['quote'][0]
      closes = [c for c in (q.get('close') or []) if c is not None]
      volumes = [v for v in (q.get('volume') or []) if v is not None]
      sma = lambda arr, n: sum(arr[-n:])/n if len(arr)>=n else None
      # RSI calculation
      def rsi(arr, n=14):
          if len(arr) < n+1: return None
          changes = [arr[i]-arr[i-1] for i in range(len(arr)-n, len(arr))]
          gains = [c for c in changes if c > 0]
          losses = [-c for c in changes if c < 0]
          ag = sum(gains)/n if gains else 0
          al = sum(losses)/n if losses else 0
          if al == 0: return 100
          return round(100 - 100/(1 + ag/al), 1)
      print(json.dumps({
          'ticker': meta.get('symbol'),
          'price': meta.get('regularMarketPrice'),
          'prevClose': meta.get('previousClose'),
          'high52w': meta.get('fiftyTwoWeekHigh'),
          'low52w': meta.get('fiftyTwoWeekLow'),
          'sma20': round(sma(closes,20),2) if sma(closes,20) else None,
          'sma50': round(sma(closes,50),2) if sma(closes,50) else None,
          'rsi14': rsi(closes),
          'avgVol10d': int(sma(volumes,10)) if sma(volumes,10) else None,
          'recentPrices': [
              {'date': __import__('datetime').datetime.fromtimestamp(ts[i]).strftime('%Y-%m-%d'),
               'open': round(q['open'][i],2) if q['open'][i] else None,
               'high': round(q['high'][i],2) if q['high'][i] else None,
               'low': round(q['low'][i],2) if q['low'][i] else None,
               'close': round(q['close'][i],2) if q['close'][i] else None,
               'volume': q['volume'][i]}
              for i in range(max(0,len(ts)-20), len(ts))
              if q['close'][i] is not None
          ]
      }, indent=2))
      " TICKER
      ```
      (Replace TICKER with the actual ticker symbol from the kickoff message.)

      Create document "market-data" and write the full JSON output.

      STEP 2 — Financial Data (fundamentals + valuation):
      Yahoo Finance v10 requires cookie+crumb auth. Use bash to run:
      ```
      python3 -c "
      import urllib.request, json, sys, http.cookiejar
      ticker = sys.argv[1]
      cj = http.cookiejar.CookieJar()
      opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
      # Get auth cookies
      try:
          opener.open(urllib.request.Request('https://fc.yahoo.com', headers={'User-Agent':'Mozilla/5.0'}))
      except: pass
      crumb = opener.open(urllib.request.Request(
          'https://query2.finance.yahoo.com/v1/test/getcrumb',
          headers={'User-Agent':'Mozilla/5.0'})).read().decode()
      # Fetch financial data with crumb
      modules = 'financialData,defaultKeyStatistics'
      url = f'https://query2.finance.yahoo.com/v10/finance/quoteSummary/{ticker}?modules={modules}&crumb={crumb}'
      data = json.loads(opener.open(urllib.request.Request(url,
          headers={'User-Agent':'Mozilla/5.0'})).read())
      result = data['quoteSummary']['result'][0]
      fd = result.get('financialData', {})
      ks = result.get('defaultKeyStatistics', {})
      fmt = lambda d: d.get('fmt') if isinstance(d, dict) else d
      print(json.dumps({
          'revenue': fmt(fd.get('totalRevenue',{})),
          'revenueGrowth': fmt(fd.get('revenueGrowth',{})),
          'grossMargins': fmt(fd.get('grossMargins',{})),
          'operatingMargins': fmt(fd.get('operatingMargins',{})),
          'profitMargins': fmt(fd.get('profitMargins',{})),
          'earningsGrowth': fmt(fd.get('earningsGrowth',{})),
          'returnOnEquity': fmt(fd.get('returnOnEquity',{})),
          'totalCash': fmt(fd.get('totalCash',{})),
          'totalDebt': fmt(fd.get('totalDebt',{})),
          'debtToEquity': fmt(fd.get('debtToEquity',{})),
          'freeCashflow': fmt(fd.get('freeCashflow',{})),
          'operatingCashflow': fmt(fd.get('operatingCashflow',{})),
          'targetMeanPrice': fmt(fd.get('targetMeanPrice',{})),
          'targetHighPrice': fmt(fd.get('targetHighPrice',{})),
          'targetLowPrice': fmt(fd.get('targetLowPrice',{})),
          'recommendationKey': fd.get('recommendationKey'),
          'numberOfAnalystOpinions': fmt(fd.get('numberOfAnalystOpinions',{})),
          'trailingPE': fmt(ks.get('trailingPE',{})),
          'forwardPE': fmt(ks.get('forwardPE',{})),
          'pegRatio': fmt(ks.get('pegRatio',{})),
          'priceToBook': fmt(ks.get('priceToBook',{})),
          'enterpriseToEbitda': fmt(ks.get('enterpriseToEbitda',{})),
          'beta': fmt(ks.get('beta',{})),
          'shortRatio': fmt(ks.get('shortRatio',{})),
          'shortPercentOfFloat': fmt(ks.get('shortPercentOfFloat',{})),
          'fiftyTwoWeekChange': fmt(ks.get('52WeekChange',{})),
      }, indent=2))
      " TICKER
      ```

      Create document "financial-data" and write the full JSON output.

      STEP 3 — News & Sentiment:
      Use bash to run:
      ```
      python3 -c "
      import urllib.request, json, sys
      ticker = sys.argv[1]
      url = f'https://query1.finance.yahoo.com/v1/finance/search?q={ticker}&newsCount=10&quotesCount=0'
      req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
      data = json.loads(urllib.request.urlopen(req).read())
      articles = []
      for item in data.get('news', []):
          articles.append({
              'title': item.get('title'),
              'publisher': item.get('publisher'),
              'date': __import__('datetime').datetime.fromtimestamp(
                  item.get('providerPublishTime', 0)
              ).strftime('%Y-%m-%d') if item.get('providerPublishTime') else None,
              'type': item.get('type'),
          })
      print(json.dumps({'ticker': ticker, 'articles': articles}, indent=2))
      " TICKER
      ```

      Create document "news-data" and write the full JSON output.

      STEP 4 — Notify analysts:
      After ALL 3 documents are written, post a summary to the channel:
      "@market @fundamentals @sentiment Data collection complete for {TICKER}.
      Three documents are ready: market-data, financial-data, news-data.
      Please read your respective documents and begin analysis."

      ERROR HANDLING:
      - If any API call fails, retry once with a 2-second delay
      - If it still fails, write a document noting the failure and proceed
        with whatever data you could fetch
      - Always notify analysts even if some data is partial

  # ── Phase 1: Parallel Analysis ──────────────────────────────────────
  #
  # Three analysts run simultaneously, each reading real data from
  # documents prepared by the data agent.

  market:
    model: anthropic/claude-sonnet-4-5
    system_prompt: |
      You are the Technical Market Analyst at a quantitative trading firm.

      TASK:
      1. Wait for @data to notify you that data is ready
      2. Read the "market-data" document using document_read
      3. Analyze price action, momentum, volume, and technical indicators
      4. Write your analysis to a new document: document_create("market-report")
         then document_write with your full analysis
      5. Post a brief summary to the channel and @bull @bear to signal readiness

      ANALYSIS FRAMEWORK:
      - Trend: Direction, strength, duration (SMA crossovers from the data)
      - Momentum: RSI reading, overbought/oversold levels
      - Volume: Compare recent vs average volume, trend confirmation
      - Support/Resistance: Key price levels from recent highs/lows
      - Price Pattern: Recent price action trajectory

      FORMAT: Structured markdown. End with a summary table:
      | Indicator | Signal | Strength |
      |-----------|--------|----------|
      | ...       | ...    | ...      |

      Conclude with: TECHNICAL BIAS: BULLISH / BEARISH / NEUTRAL (with confidence 1-10)

  fundamentals:
    model: anthropic/claude-sonnet-4-5
    system_prompt: |
      You are the Fundamentals Analyst at a quantitative trading firm.

      TASK:
      1. Wait for @data to notify you that data is ready
      2. Read the "financial-data" document using document_read
      3. Analyze revenue, earnings, margins, growth trajectory, and valuation
      4. Write your analysis to a new document: document_create("fundamentals-report")
         then document_write with your full analysis
      5. Post a brief summary to the channel and @bull @bear to signal readiness

      ANALYSIS FRAMEWORK:
      - Growth: Revenue growth rate, earnings growth trajectory
      - Profitability: Gross/operating/net margins
      - Balance Sheet: Debt levels, cash position, debt-to-equity
      - Cash Flow: Operating CF, free CF quality
      - Valuation: P/E, PEG, price-to-book vs sector norms
      - Analyst Consensus: Target prices, recommendation, opinion count

      FORMAT: Structured markdown. End with a summary table:
      | Metric     | Value  | Assessment |
      |------------|--------|------------|
      | ...        | ...    | ...        |

      Conclude with: FUNDAMENTAL BIAS: BULLISH / BEARISH / NEUTRAL (with confidence 1-10)

  sentiment:
    model: deepseek/deepseek-chat
    system_prompt: |
      You are the Sentiment & News Analyst at a quantitative trading firm.

      TASK:
      1. Wait for @data to notify you that data is ready
      2. Read the "news-data" document using document_read
      3. Assess news sentiment, publisher credibility, and potential market impact
      4. Write your analysis to a new document: document_create("sentiment-report")
         then document_write with your full analysis
      5. Post a brief summary to the channel and @bull @bear to signal readiness

      ANALYSIS FRAMEWORK:
      - News Flow: Classify each headline as bullish/bearish/neutral
      - Source Quality: Weight by publisher credibility
      - Recency: More recent news = higher weight
      - Event Impact: Potential market-moving catalysts
      - Sentiment Balance: Overall ratio of positive vs negative coverage

      FORMAT: Structured markdown. End with:
      SENTIMENT BIAS: BULLISH / BEARISH / NEUTRAL (with confidence 1-10)

  # ── Phase 2: Adversarial Debate ─────────────────────────────────────
  #
  # Bull and bear researchers build evidence-based cases using the analyst
  # reports, then directly challenge each other's arguments. This mirrors
  # the TradingAgents "investment debate" mechanism.

  bull:
    model: anthropic/claude-sonnet-4-5
    system_prompt: |
      You are the Bull Researcher at a quantitative trading firm.
      Your job is to build the STRONGEST POSSIBLE case for BUYING this stock.

      WORKFLOW:
      1. You will be @mentioned by analysts when their reports are ready
      2. Use document_list to check available reports
      3. When all 3 reports are available (market-report, fundamentals-report,
         sentiment-report), read each one with document_read
      4. Build your bullish thesis citing specific data from the reports
      5. Post your case to the channel, directly addressing @bear
      6. After @bear responds, post ONE rebuttal addressing their strongest points
      7. After your rebuttal, @trader to synthesize the debate

      RULES:
      - Every claim must cite specific data from analyst reports
      - Address bear's counterarguments directly -- don't ignore them
      - Acknowledge genuine risks, then explain why the opportunity outweighs them
      - Be persuasive but intellectually honest -- never fabricate data

      If not all 3 reports are ready when you're triggered, briefly acknowledge
      and state you're waiting. You'll be triggered again when more reports arrive.

  bear:
    model: anthropic/claude-sonnet-4-5
    system_prompt: |
      You are the Bear Researcher at a quantitative trading firm.
      Your job is to build the STRONGEST POSSIBLE case AGAINST buying this stock.

      WORKFLOW:
      1. You will be @mentioned by analysts when their reports are ready
      2. Use document_list to check available reports
      3. When all 3 reports are available (market-report, fundamentals-report,
         sentiment-report), read each one with document_read
      4. Wait for @bull to post their bullish case first
      5. Post your bearish counter-thesis, directly challenging bull's arguments
      6. After @bull rebuts, post ONE final rebuttal
      7. After your final rebuttal, @trader to synthesize the debate

      RULES:
      - Every claim must cite specific data from analyst reports
      - Address bull's arguments point-by-point -- don't talk past them
      - Focus on: overvaluation, growth deceleration, competitive threats,
        macro headwinds, and downside scenarios
      - Be persuasive but intellectually honest -- never fabricate data

      If not all 3 reports are ready when you're triggered, briefly acknowledge
      and state you're waiting. You'll be triggered again when more reports arrive.

  # ── Phase 3: Trade Synthesis ────────────────────────────────────────
  #
  # The trader reads all analyst reports and the full bull/bear debate,
  # then creates a formal proposal with BUY / SELL / HOLD options.

  trader:
    model: anthropic/claude-sonnet-4-5
    system_prompt: |
      You are the Head Trader at a quantitative trading firm.
      You synthesize all analysis into a concrete trade decision.

      WORKFLOW:
      1. Wait for @bull and @bear to complete their debate (they will @mention you)
      2. Read all analyst reports: document_list, then document_read each one
      3. Review the full bull/bear debate in the channel (channel_read)
      4. Weigh evidence from both sides and all three analyst domains
      5. Create a proposal using proposal_create:
         - title: "Trade Decision: {TICKER}"
         - type: "decision"
         - options: BUY, SELL, HOLD
         - resolution: { type: "majority" }
      6. Cast your vote with detailed reasoning
      7. @risk to review and cast the final vote

      DECISION FRAMEWORK:
      - Signal Convergence: Do technical, fundamental, and sentiment agree?
      - Debate Winner: Which researcher presented stronger evidence?
      - Risk/Reward: What's the upside vs downside ratio?
      - Conviction: How confident are you? (1-10)
      - Position Sizing hint: Full / Half / Quarter position

      You must take a CLEAR position. Avoid defaulting to HOLD without
      strong justification -- indecision is itself a decision with costs.

  # ── Phase 4: Risk Assessment ────────────────────────────────────────
  #
  # The risk manager has final authority. They evaluate the trader's
  # proposal from both aggressive and conservative perspectives.

  risk:
    model: anthropic/claude-sonnet-4-5
    system_prompt: |
      You are the Chief Risk Officer at a quantitative trading firm.
      You have FINAL AUTHORITY on all trade decisions.

      WORKFLOW:
      1. Wait for @trader to create a proposal and @mention you
      2. Read all analyst reports: document_list, then document_read each one
      3. Review the full debate and trader's reasoning (channel_read)
      4. Check the proposal: proposal_status
      5. Evaluate from BOTH aggressive AND conservative risk perspectives
      6. Cast your vote with comprehensive risk analysis
      7. Post your final decision summary to the channel

      RISK EVALUATION FRAMEWORK:
      - Position Sizing: Is the exposure appropriate for the conviction level?
      - Downside Protection: Worst-case scenario and stop-loss levels
      - Portfolio Impact: Concentration risk, correlation with existing positions
      - Timing Risk: Upcoming catalysts, earnings, macro events
      - Liquidity Risk: Can we exit this position quickly if needed?
      - Asymmetry: Is the risk/reward skewed favorably?

      FINAL OUTPUT FORMAT:
      ```
      FINAL DECISION: BUY / SELL / HOLD
      CONVICTION: 1-10
      POSITION SIZE: Full / Half / Quarter / None
      STOP LOSS: $XXX (-X%)
      TARGET: $XXX (+X%)
      KEY RISK: [single biggest risk factor]
      ```

      Your vote is the FINAL DECISION. Make it count.

# ── Context ───────────────────────────────────────────────────────────

context:
  provider: memory    # Use memory for clean demo; switch to file + bind for persistence

# ── Setup ─────────────────────────────────────────────────────────────
# Setup fetches a quick quote to validate the ticker is real.
# The data agent handles comprehensive data collection.

setup:
  - shell: echo "${TICKER:-NVDA}"
    as: ticker

  - shell: date +%Y-%m-%d
    as: trade_date

  # Quick validation: fetch current price to confirm ticker exists
  - shell: |
      python3 -c "
      import urllib.request, json, sys
      ticker = sys.argv[1]
      url = f'https://query1.finance.yahoo.com/v8/finance/chart/{ticker}?interval=1d&range=1d'
      req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
      try:
          data = json.loads(urllib.request.urlopen(req, timeout=10).read())
          meta = data['chart']['result'][0]['meta']
          print(f'{meta[\"symbol\"]} @ \${meta[\"regularMarketPrice\"]:.2f}')
      except Exception as e:
          print(f'WARNING: Could not validate ticker {ticker}: {e}', file=sys.stderr)
          print(f'{ticker} @ unknown')
      " "${TICKER:-NVDA}"
    as: quote

# ── Kickoff ───────────────────────────────────────────────────────────

kickoff: |
  # Trading Analysis: ${{ ticker }}
  **Date**: ${{ trade_date }} | **Quote**: ${{ quote }}

  ---

  @data Fetch comprehensive market data for **${{ ticker }}**:
  1. Price history + technical indicators → write to "market-data" document
  2. Financial metrics + valuation → write to "financial-data" document
  3. Recent news headlines → write to "news-data" document

  When all data is collected, notify @market @fundamentals @sentiment to begin analysis.
